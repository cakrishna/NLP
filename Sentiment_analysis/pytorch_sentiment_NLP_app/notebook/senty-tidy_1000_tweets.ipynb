{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9e514b6-0992-41aa-92eb-a2cbea307424",
   "metadata": {},
   "source": [
    "### load Data\n",
    "- airline_sentiment daset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fb1d4d0-9504-4c3c-b672-74f34894322b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.703061e+17</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>virginamerica dhepburn say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.703011e+17</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>virginamerica plus add commercial experience t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.703011e+17</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "      <td>virginamerica not today must mean need take an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>virginamerica really aggressive blast obnoxiou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.703008e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>virginamerica really big bad thing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0           0  5.703061e+17           neutral                        1.0000   \n",
       "1           1  5.703011e+17          positive                        0.3486   \n",
       "2           2  5.703011e+17           neutral                        0.6837   \n",
       "3           3  5.703010e+17          negative                        1.0000   \n",
       "4           4  5.703008e+17          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "   airline_sentiment_gold        name  negativereason_gold  retweet_count  \\\n",
       "0                     NaN     cairdin                  NaN              0   \n",
       "1                     NaN    jnardino                  NaN              0   \n",
       "2                     NaN  yvonnalynn                  NaN              0   \n",
       "3                     NaN    jnardino                  NaN              0   \n",
       "4                     NaN    jnardino                  NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \\\n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)   \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)   \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)   \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)   \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0                         virginamerica dhepburn say  \n",
       "1  virginamerica plus add commercial experience t...  \n",
       "2  virginamerica not today must mean need take an...  \n",
       "3  virginamerica really aggressive blast obnoxiou...  \n",
       "4                 virginamerica really big bad thing  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset in Jupyter notebook:\n",
    "import pandas as pd\n",
    "\n",
    "data_tidy = pd.read_csv('tidy_1000_tweets.csv') # Load the dataset\n",
    "\n",
    "data_tidy.head() # Display the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cca434fa-9838-4839-b0bb-d698b2cd2f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>virginamerica dhepburn say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>virginamerica plus add commercial experience t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>virginamerica not today must mean need take an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>virginamerica really aggressive blast obnoxiou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>virginamerica really big bad thing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                       cleaned_text\n",
       "0           neutral                         virginamerica dhepburn say\n",
       "1          positive  virginamerica plus add commercial experience t...\n",
       "2           neutral  virginamerica not today must mean need take an...\n",
       "3          negative  virginamerica really aggressive blast obnoxiou...\n",
       "4          negative                 virginamerica really big bad thing"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data_tidy[[\"airline_sentiment\",\"cleaned_text\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c81ef5fc-adf8-40e4-8156-6a8c362335aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preperation\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0ceed88-cd91-4867-889c-3980a82f1861",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, texts, labels, tokenizer, max_len=512):\n",
    "    self.texts = texts\n",
    "    self.labels = labels\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.texts)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    text = str(self.texts[idx])\n",
    "    label = torch.tensor(self.labels[idx])\n",
    "\n",
    "    encoding = self.tokenizer(text, truncation=True, padding=\"max_length\",\n",
    "                              max_length=self.max_len)\n",
    "\n",
    "    return {\n",
    "        'input_ids': encoding['input_ids'],\n",
    "        'attention_mask': encoding['attention_mask'],\n",
    "        'labels': label\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f68160b3-088a-418c-a599-6b859237e8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aks/miniconda3/envs/nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# prepare tokenizer and model\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = 'distilbert-base-uncased'\n",
    "# device = \"cuda\"\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3567854f-1dfd-4d97-944d-372981681f2f",
   "metadata": {},
   "source": [
    "### pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27e78031-b75a-49a0-b03a-a0b19e199e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imdb has two columns review, sentiment(positive, negative)\n",
    "# tweets we have cleand_text is review, airline_sentiment(negative, neutral, positive)\n",
    "X = data['cleaned_text'].tolist()\n",
    "\n",
    "label2id = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "id2label = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "\n",
    "y = data['airline_sentiment'].map(label2id).tolist()\n",
    "\n",
    "dataset = CustomDataset(X, y, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86070a32-8b98-44b4-ae2e-587360aa4ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1677628c-4024-4986-bafb-22989df49c1d",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc52ab08-1025-4fe7-949b-8edaa55e8332",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5565c101-7793-41ef-a237-b014a0b83e29",
   "metadata": {},
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "def compute_metrics(example):\n",
    "  labels = example.label_ids\n",
    "  preds = example.predictions.argmax(-1)\n",
    "\n",
    "  f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "  acc = accuracy_score(labels, preds)\n",
    "\n",
    "  return {'accuracy': acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd9607bb-0c45-4809-9980-b79fc4b4c9ef",
   "metadata": {},
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "batch_size = 4\n",
    "model_name = \"distilbert_finetuned_setiment\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir = \"output\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size = batch_size,\n",
    "    learning_rate = 2e-5,\n",
    "    num_train_epochs = 5,\n",
    "    evaluation_strategy = 'epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9846ec5a-7e6d-4730-93b0-a560dd258c6b",
   "metadata": {},
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  args=args,\n",
    "                  train_dataset = train_dataset,\n",
    "                  eval_dataset = test_dataset,\n",
    "                  compute_metrics=compute_metrics,\n",
    "                  tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "445c18de-c0ff-4e50-a87f-4d37a9d57eb7",
   "metadata": {},
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "86da889c-8052-4e3d-9204-f2a5fcfe6619",
   "metadata": {},
   "source": [
    "# Evaluate the Model\n",
    "results = trainer.evaluate(test_dataset)\n",
    "\n",
    "print(\"Evaluation Results:\")\n",
    "print(f\"  - Loss: {results['eval_loss']:.4f}\")\n",
    "print(f\"  - Runtime: {results['eval_runtime']:.2f} seconds\")\n",
    "print(f\"  - Samples per Second: {results['eval_samples_per_second']:.2f}\")\n",
    "print(f\"  - Steps per Second: {results['eval_steps_per_second']:.2f}\")\n",
    "print(f\"  - Epoch: {results['epoch']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3e6372-114c-48b7-8995-2872b19b3521",
   "metadata": {},
   "source": [
    "### 2nd way for args and merics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c52d10e-db6a-4f8a-80e7-f1c7bfcca7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name} - {'Training' if param.requires_grad else 'Frozen'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc3639e3-4d96-4470-803b-fc7f96321ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data collator\n",
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5e0cd8c-333f-4360-8bc4-a64918abbe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    load_acc = load_metric('accuracy')\n",
    "    load_f1 = load_metric('f1')\n",
    "    logits,labels = eval_pred\n",
    "    predictions = np.argmax(logits,axis = -1)\n",
    "    acc = load_acc.compute(predictions = predictions,references = labels)['accuracy']\n",
    "    f1 = load_f1.compute(predictions = predictions, references = labels)['f1']\n",
    "    return {'acc':acc,'f1':f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ff8f1f8-a6bb-4358-83cb-2b7a87392022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aks/miniconda3/envs/nlp/lib/python3.10/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './output/',\n",
    "    learning_rate=2e-5,\n",
    "    seed=11,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    eval_steps=600,\n",
    "    save_steps=600,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f3594eb-489b-4c37-ae16-ebf82f118e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_496/3023488113.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e15899ba-24d3-4aee-b3b0-116d972706d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 02:46, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=0.7903514099121094, metrics={'train_runtime': 168.3048, 'train_samples_per_second': 19.013, 'train_steps_per_second': 1.188, 'total_flos': 423903235276800.0, 'train_loss': 0.7903514099121094, 'epoch': 4.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55fffacb-7f93-4a7b-80b5-a1bf1fa6ee8f",
   "metadata": {},
   "source": [
    "# Evaluate the Model\n",
    "results = trainer.evaluate(test_dataset)\n",
    "\n",
    "print(\"Evaluation Results:\")\n",
    "print(f\"  - Loss: {results['eval_loss']:.4f}\")\n",
    "print(f\"  - Runtime: {results['eval_runtime']:.2f} seconds\")\n",
    "print(f\"  - Samples per Second: {results['eval_samples_per_second']:.2f}\")\n",
    "print(f\"  - Steps per Second: {results['eval_steps_per_second']:.2f}\")\n",
    "print(f\"  - Epoch: {results['epoch']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f96a612-b44b-4ccb-823d-bb157c27869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert_finetuned_setiment2\"\n",
    "trainer.save_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e15b90-63c0-4124-930e-693f267b71d3",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "320d7697-ff4d-40e8-a482-3bd27dfe0525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis with the pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "# sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# data = ['i love you', 'i hate you']\n",
    "# sentiment_pipeline(data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f8d95f09-4f61-4b2b-9600-85fdce78bf6e",
   "metadata": {},
   "source": [
    "text = \"i love this product\"\n",
    "pipe = pipeline('text-classification', model=model_name, tokenizer=tokenizer)\n",
    "pipe(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce549547-52cb-44de-abf4-fc66585c2c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'negative', 1: 'neutral', 2: 'positive'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04272f2f-09f4-457e-8937-d65cfb0e9b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "tok = AutoTokenizer.from_pretrained(model_name)\n",
    "mod = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78a16445-1f89-4d6e-b2bc-0eaf4c7f1c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_2', 'score': 0.5791122317314148}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text0 = \"hate the airline\"\n",
    "text1 = \"love the airline\"\n",
    "text2 = \"virginamerica plus add commercial experience tacky\"\n",
    "\n",
    "pipe = pipeline('text-classification', model=mod, tokenizer=tok)\n",
    "pipe(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "059390f9-d747-4913-a56b-abe8d5c63068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.6335480809211731}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text0 = \"hate the airline\"\n",
    "# text1 = \"love the airline\"\n",
    "# text2 = \"virginamerica plus add commercial experience tacky\"\n",
    "\n",
    "pipe = pipeline('text-classification', model=mod, tokenizer=tok)\n",
    "pipe(text0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ad8bd95-53f5-4f76-91bc-44424d32ec62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.5199728608131409}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"virginamerica dhepburn say\"\n",
    "# text1 = \"love the airline\"\n",
    "# text2 = \"virginamerica plus add commercial experience tacky\"\n",
    "\n",
    "pipe = pipeline('text-classification', model=mod, tokenizer=tok)\n",
    "pipe(text1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c39bdd03-1e7e-4ca9-ae28-dfc624f30b41",
   "metadata": {},
   "source": [
    "def get_prediction(text):\n",
    "  input_ids = tok.encode(text, return_tensors='pt')\n",
    "  output = mod(input_ids)\n",
    "\n",
    "  preds = torch.nn.functional.softmax(output.logits, dim=-1)\n",
    "\n",
    "  prob = torch.max(preds).item()\n",
    "\n",
    "  idx = torch.argmax(preds).item()\n",
    "  sentiment = id2label[idx]\n",
    "\n",
    "  return {'sentiment':sentiment, 'prob':prob}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "620caddd-1b8e-4111-b14f-7bd585ecfa18",
   "metadata": {},
   "source": [
    "text = \"hate the airline\"\n",
    "get_prediction(text)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "54fae6c0-7bef-4150-b923-9d592204930e",
   "metadata": {},
   "source": [
    "text = \"virginamerica plus add commercial experience tacky\"\n",
    "get_prediction(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcab2cde-930c-45da-a369-32fc9692576e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
